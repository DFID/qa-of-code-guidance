[
["index.html", "QA of Code Chapter 1 QA for Coding Struture 1.1 Pages 1.2 Terminlogy", " QA of Code Joshua Halls 2019-07-29 Chapter 1 QA for Coding Struture RAP Testing Coding Guidelines Documentation GIT 1.1 Pages Aiming for roughly 10 pages Each page should aim for around 300 - 400 words per page Was thinking that it would be possible to produce this guidance in markdown? That way we could include code chunks, maybe hide them Introduction Who is this for it is for the QA of statistics code, in open source languages mainly RAP Overview Minimal RAP?? Level of RAP Examples? One example, lower profile statistic, just long code scripts, basic git, no testing Second example, higher profile, more advanced along RAP stages, uses more advanced git/branching, testing, functions etc Rap QA process Testing Why you should test your code What you should you test How do you know that your code is good without testing Testing Strategies Unit Testing Check list for standard things to test Boundary Value Analysis Examples! Version Control with Git Why use Git Advantages of using Git version control Branching Roll back issues pull requests Peer review, share code other benefits! Peer Review internal / external other team members access to data Documentation Documenting code, inline documenting Readme for projects documenting function, in and out of packages Markdown for desk notes coding standards documentation standards Environment- Making sure that reproducible code can actually be reproduced!! DATA- synthetic data, how peer review? produce dummy data? Docker Packrat Documentation Other Issues Staff leave? Need to train up new people, documentation makes it easier. Project need to be manageable for running in the long run Code Standards Link to resources Role and responsibility Terminology Managers 1.2 Terminlogy GIT SHELL VC Repository CLI GUI Unit Test "],
["rap.html", "Chapter 2 RAP", " Chapter 2 RAP 2.0.1 Why make our work reproducible? Producing official statistics can be time-consuming and painstaking as we need to make sure that our outputs are both accurate and timely. Reproducible analysis is about opening up the production process so that anybody can follow the steps we took and understand how we got to the results that we publish. By making our analysis reproducible, we make it easier for others to quality assure, assess, critique and re-use our methods and results, and for colleagues to test and validate what we have done. In a reproducible workflow, we bring together the code and the data that we used to generate our results. This lets us be fully open about the decisions we made as we generated our outputs so that other analysts can follow what we did and re-create them. Reproducible analysis supports the requirements of the Code of Practice for Statistics around quality assurance and transparency, as, wherever possible, we share the code we used to build the outputs, along with enough data to allow for proper testing. 2.0.2 What is a reproducible analytical pipeline? Across government we aim to create effective and efficient statistical workflows which are repeatable over time and follow the principles of reproducible analysis. We call these Reproducible Analytically Pipelines (RAP). Producing statistics in a reproducible way is quite a new idea for government. Many analysts still use proprietary (paid-for) analytical tools like SAS or SPSS in combination with programs like Excel, Word or Acrobat to create statistical products. The processes for creating statistics this way are usually manual or semi-manual. Colleagues typically repeat parts of the process manually to quality assure the outputs. This way of working is time consuming and can be frustrating because the manual steps can be quite hard to replicate quickly. Work flows are also prone to error, because the input data and the outputs are not connected directly, only through the analyst’s manual intervention. More recently, the tools and techniques available to analysts have evolved. Open-source tools like Python and R, coupled with the use of version control tools such as Git, used widely in software engineering to make it easier to collaborate, have made it possible to develop more automatic, streamlined processes, accompanied by a full audit trail. RAP was first piloted in the GSS in 2017 by analysts in the Department for Digital, Culture, Media &amp; Sport (DCMS) and the Department for Education (DfE). They collaborated with data scientists from the Government Digital Service (GDS) to automate the production of statistical bulletins. To support the adoption of RAP across government, there is a network of RAP champions. Champions are responsible for promoting reproducible analysis and the use of reproducible analytical pipelines and supporting others who want to develop RAP in their own teams. More information on "],
["levels-of-rap.html", "Chapter 3 Levels of RAP", " Chapter 3 Levels of RAP RAP can be viewed as a process, starting with a basic coding project and adding additional levels of enhancement to the project as you go. This process gives a framework for progressing and how far you get depends on the skill level within your team, the infrastructure available in your department and even how necessary the later steps are for your project. For one off pieces of work then the later steps might be time consuming with minimal benefit. However for regular work you are going to repeat then the more levels you can add the more secure you will be that your code is preforming as you expect it to. This process should be pragmatic and proportionate. You may think about a minimal level that you hope to achieve before the code is put into production, but this level will vary depending on your needs. This piece of guidance will go through many of the steps. "],
["testing.html", "Chapter 4 Testing", " Chapter 4 Testing When you are working on a project how do you know that your code is doing what you expect it to do? You run it and look at the output. This is a manual test and it has it’s limitations. Hadley Wickham in The R Journal it’s not that we don’t test our code, it’s that we don’t store our tests so they can be re-run automatically. Manual tests need to be constantly re-run. This is achievable when your code is small but when it becomes longer this is time consuming. When you come back to your code in the future you will have forgotten what tests you have run, any changes are then liable to break something. Fundamentally if you don’t test your code then how do you know that your code is doing what it is suppose to? Just as data validation in an important step in statistics to the the data is correct, code validation with testing is important to check that the process is correct. 4.0.1 Advantages of testing your code Better Code Structure - Writing tests forces you to separate code into functions that are separate and isolated, reducing duplication in your code. This approach will make your code easier to test and also easier to understand and use. Less Bugs - Like double entry book keeping the behavior of your code is specified twice in the code and the test making it less error prone. More Robust Code - If all the major functions of your code have associated tests then you can change your code without worrying that you have broken something without realizing Decreased Frustration - Untested code is precarious, an making changes without knowing if you have broken a section is stress inducing. Being able to deploy code that you are confident will work because it is tested will make the process more productive. 4.0.2 When should you use testing In a Analytics pipeline. In general if you are going to reuse your code multiple times then it needs to be tested to ensure that it is working properly. In a Important piece of work such as a National Statistic. It is important that National Statistics are correct and that the public has confidence in the validity of published work, testing is important to ensure that the code is working as expected and prevents errors building confidence. When working in a team. Testing ensures that collaborators can alter the code without worrying about breaking the code without realizing. 4.0.3 When should you not use testing One off pieces of work, the effort may not be worth the benefit Exploratory work. If you are experimenting and are not sure whether your work will be converted into permanent project then testing may not be appropriate. There would be a benefit to testing if a exploratory project turns into a permanent one, however the code may be changed so fundamentally that all the tests would have to be re written. Fundamentally it is a trade off. "],
["testing-frameworks.html", "Chapter 5 Testing Frameworks 5.1 What excatly is a test 5.2 Refernces", " Chapter 5 Testing Frameworks 5.1 What excatly is a test Testing is just checking that the expected result is the same as the actual result. Automated testing is moving from doing this in a informal ad-hoc way to an automated process which is repeatable. Tests should be Fast Independent Repeatable (deterministic) Self-validating (no manual steps) Thorough (How much do you trust they cover everything?) 5.1.1 Unit Test 5.1.2 Intergration Tests 5.1.3 Test Driven Development 5.2 Refernces Testing Blog Testthat "],
["git.html", "Chapter 6 GIT", " Chapter 6 GIT What is GIT What is VC How to use GIT ( CLI or GUI) Typical GIT workflow Branching 6.0.1 Git Introduction Git is a version control system, a tool that tracks changes to your code and shares those changes with others. Git is most useful when combined with GitHub, a website that allows you to share your code with the world, solicit improvements via pull requests and track issues. 6.0.2 About Version Control Version control is a system that records changes to a file or set of files over time so that you can recall specific versions later. This means that changes can be examined allowing a record to kept of who changed what. The changes can also be reversed, allowing your code to be rolled back to an earlier state. GIT is an immensely popular tool in the data science community for VC. 6.0.3 What is GIT Git is a version control system, a tool that tracks changes to your code and shares those changes with others. To start a common mistake is to get Git and it’s hosting services mixed up, Git is not GitHub or GitLab, they are websites for hosting projects using git. Git is a Distributed VC, meaning that you will have a local repository which has a special folder inside called .git. You will normally, but don’t have too, have a remote, central repository where you and collaborators can contribute code, this could be on GitHub, GitLab or elsewhere. You and any collaborators have an exact clone of the repository on your local computer. 6.0.4 How does GIT actually work You are probably familiar with the windows file system. Imagine a folder with some files/data in it. We can make the folder into a Git repository. When we do this Git will keep track of any changes you make to the files, and therefore allow you to see who has changed the files, work with other people on the files and undo any changes. Git thinks of the data as a series of snapshots of a mini file system (the folder). At any time you can take a snapshot, by saving or committing, and git will take a snapshot of what your files look like at that moment, and stores a reference to that snapshot. Git thinks about the data as a stream of snapshots. To actually run Git there are two methods CLI Command Line Interface GUI Graphical User Interface A GUI is effectively a program that will run git for you. However these only implement a subset of git commands and it is generally recommend to run Git on the command line. To do this you need to get a terminal and Git installed. This is easier than it sounds. A popular method is to get GitBash. This is a terminal interface with Git installed. If you are unfamiliar with running terminal commands there are alot of great online resources, and fundamentally you will only need a handful of commands to run what you need. If you don;t want to learn past that you won’t need to. 6.0.5 Typical Git workflow There are many ways to get a Git repository started. I will discuss turning your folder into a repository. First we need to initialize Git, we can do that with the command git init All git command start with git followed by the command. This will set-up the folder as a git repository, easy! Git won;t actually track any of the files yet, as we haven’t got any snapshots. We do this in two steps. First we add the files we want to be tracked to stage them to be committed. git add . This uses the command add to select the files we want to prepare to track, and . selects all files in the folder. Only do this if you want to track every file! Otherwise replace . with the filename you want such as git add data.csv Now the files are staged for the next commit, we want to take the snapshot. To commit we run git commit -m &quot;a helpful commit comment, anything you want!&quot; This runs the commit command which we take the snapshot. -m tells the commit that we want to leave a message and everything in \"\" is attached as a commit comment. Make this something informative and helpful, as you will want to later look back at these, and others will see them too. That is the basic git workflow for working by yourself. You can then edit the files however you want, e.g in Microsoft word or using R studio, and when you next want to take a snapshot run the command again git add . git commit -m &quot;another informative comment&quot; We can also check on the status of our repository with git status 6.0.6 Remote Repostory Using Git just on your computer is useful for being able to roll back or reverse to previous commits, and for keeping track of what changes you made. But Git is really powerful when combined with a remote repository. This basically creates a clone or identical copy of your git repository (all the files in it) and hosts it on another computer, probably on a website such as GitHub or Gitlab. This allows others to also make a copy of the code, to modify and share there changes with you whilst git keeps track. This is a useful tool for peer review and collaborator coding. it is also a backup if your laptop dies or is lost, as the data is safely stored elsewhere too. To do this is simple. First you need to setup a repository on a hosting site. Follow the instructions on GitHub or elsewhere on how to do this, it is not difficult. However make it an empty repository, no README file. Next we need to connect our git repository to the remote repository. Open a Shell and run: git remote add origin https://github.com/username/reponame This command is a bit more complex but you will only need to run it once. remote add is telling git to add a remote repository to the current git. origin will be the name of the remote repository. https://github.com/username/reponame is the URL of the repository. You will be able to on GitHub or gitlab copy and paste this into the terminal window. Now we have a remote repository added we can push our code to it. The typical workflow is the same but with an added step. First we add our files to be staged, we then commit them taking a snapshot of what the current folder looks like, and then we push this snapshot to the remote repository. git add . git commit -m &quot;helpful and informative commit comment&quot; git push Now if you go to the website you will be able to see your code. If a collaborator now wants to get an exact copy of code they can clone the repository. The folder will be copied onto their computer. git clone https://github.com/username/reponame They run this command on their computer and they will now have the files and you can both work together by following the regular workflow. At this stage there will be your repository, a remote repository on a website and a third repository on a collaborator laptop. 6.0.7 Branching Branching and merging is what makes Git so powerful and for what it has been optimized for, being a distributed version control system (VCS). Branching is one of the key features of Git. It allows you to diverge from the main lien of development. You might want to do this to run an experiment which you are not sure will work, such as rewriting a section of the code, which you will incorporate only if it succeeds. Yo may create a branch for new features, which are siloed until they are ready to be incorporated. Branching allows you to control the layout of your project and it is a useful tool for working collaboratively as a project can be broken into sections which are worked on branches and incorporated when ready. You can switch back and forth to the original “master branch” or to any other branch whenever is needed. When you work using Git you will always be on a branch. by default when you setup Git it automatically creates a “master” branch. If you want to develop a new feature or section you can easily create a new branch: git branch new_branch_name git checkout new_branch_name branch followed by a name will create a branch with that name and checkout followed by a name of an existing branch will switch to it. If you want to fold the code on a branch into another to combine the project onto branch this can be done by merging. To fold the code on the new branch into he master branch then you need to move onto the master branch and then merge. git checkout master git merge new_branch_name 6.0.8 Pull Request and issues Pull requests let you tell others about changes you’ve pushed to a branch in a repository on GitHub or GitLab. Once a pull request is opened, you can discuss and review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch. This is a powerful tool for managing a project and for peer review of code. Team members can work on code on a branch and when they are done open a pull request to merge the branch into the main master branch. Another team member will review this code and can either agree to merge, or post comments on potential improvements. This back and forth ensures errors are found early and in general improves the quality of the project code. This process ensures on high quality code makes it into production. Issues are another method of discussing your code and are a great way to keep track of tasks, bugs or enchantments. For example if there is a section of messy, hard to read code then a issue could be left to rewrite that section. The issue could be general or assigned to an individual with a due date. This is another useful method for managing a coding project. "],
["coding-guidelines.html", "Chapter 7 Coding Guidelines 7.1 Why Useful 7.2 Best Practices to follow 7.3 9 Principles", " Chapter 7 Coding Guidelines Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread. – The Tidyverse Style Guide by Hadley Wickham Best practices are more about what code you write than how you write it. For example, there are many ways to access databases, but one particular way might be considered ‘best practice’ so that everyone in a team knows how it works and doesn’t have to learn other methods. 7.1 Why Useful 7.2 Best Practices to follow 7.3 9 Principles Best Practice in Programming for Data Scientists: "]
]
